---
tags:
  - Python
  - 爬虫
  - 八爪鱼
author: WangXinYi
img: /images/homePage/爬虫.webp
summary: Python爬虫与八爪鱼
categories:
  - Python
  - 爬虫
  - 八爪鱼
typora-root-url: ..
date: 2022-10-24 12:06:57
---

# 爬虫

## Python采集免费IP代理

### 一、网站分析与请求数据

```
dict = {'http': 'http://' + IP:端口号}
```

下载 requests包

```
pip install requests
```

请求数据

```python
import requests
url = 'https://www.kuaidaili.com/free/'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.42'
}
response = requests.get(url = url,headers = headers)
print(response.text)
```

### 二、解析数据

解析数据的3种写法

#### 1、可以使用re正则提取数据

```python
import re
IP_list = re.findall('<td data-title="IP">(.*?)</td>',response.text)
Post_list = re.findall('<td data-title="PORT">(.*?)</td>',response.text)
```

#### 2、CSS提取数据

```
pip install parsel
```

转换数据类型,根据标签层层定位

```python
import parsel
selector = parsel.Selector(response.text)
IP_list = selector.css('#list tbody tr td:nth-child(1)::text').getall()
Post_list = selector.css('#list tbody tr td:nth-child(2)::text').getall()
print(IP_list)
print(Post_list)
```

#### 3、xpath提取数据

```
pip install parsel
```

转换数据类型,根据标签层层定位

```python
import parsel
selector = parsel.Selector(response.text)
IP_list = selector.xpath('//*[@id ="list"]//tbody/tr/td[1]/text()').getall()
Post_list = selector.xpath('//*[@id ="list"]//tbody/tr/td[2]/text()').getall()
```

### 三、检测IP并进行打印

```python
all_list = []
use_list = []
err_list = []
num = 0
for page in range(1,11):
    url = f'https://www.kuaidaili.com/free/inha/{page}/'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.42'
    }
    response = requests.get(url = url,headers = headers)
    IP_list = re.findall('<td data-title="IP">(.*?)</td>',response.text)
    Post_list = re.findall('<td data-title="PORT">(.*?)</td>',response.text)
    for IP,Post in zip(IP_list,Post_list):
        dict = {'http': 'http://' + IP + ':' + Post}
        all_list.append(dict)
        try:
            num += 1
            checkResponse = requests.get(url='https://www.baidu.com/',headers = headers,proxies = dict)
            if checkResponse.status_code == 200:
                if(num % 20 == 0):
                    print(f'已采集有效代理{num}条')
                use_list.append(dict)
        except:
            err_list.append(dict)
print(f'一共采集到{len(all_list)}条代理,其中有效代理{len(use_list)}条')


```

### 四、保存IP

```python
with open('target.txt',mode='r',encoding = 'utf-8') as f:
	f.write('\n'.join([str(i) for i in use_list]))
    print("已保存为可用http代理.txt")
```

## 八爪鱼

**1. 打开网页**

所有的采集默认第一项都是打开网页。所以在新建任务之后，系统会提示你输入网址。当你输入之后，八爪鱼就会自动建立一个“打开网页”的流程。

**2. 点击元素**

这里元素的定义比较广泛，它可以是某个按钮，或者某个链接，也或者是某个图片或文字。使用这个步骤是你在搜索或者提交某个请求。当你点击元素后，八爪鱼会提示你想要达到的目的：点击该按钮、采集该元素文本、还是鼠标移到该链接上。然后再选择“点击该按钮”进行确认即可。

如果我们点击某个元素的目的是循环翻页，或者提取数据，那么在点击之后，八爪鱼会确认你的目的，你只要点击相关的按钮即可。

**3. 循环翻页**

很多数据都存在翻页的情况，通常你需要找到翻页的位置，比如网页底部的“下一页”按钮，点击它，会提示你“循环点击下一页”、“采集该链接文本”还是“点击该链接”。你需要确认这里是进行的“循环点击下一页”。

**4. 提取数据**

在网页上选择你想要提取的页面范围，鼠标移动到页面上会呈现蓝色的阴影面积，它表明了你想提取的数据范围。然后点击鼠标后，在右侧选择“采集数据”即可。

这4个基本操作就像它们的名称一样简单直接，这里我给你一些使用的建议：

1. 尽量使用用户操作视角进行模拟的方式进行操作，而不是在“流程视图”中手动创建相应的步骤。因为八爪鱼最大的特点就是所见即所得，所以一切就按照用户使用的流程进行操作即可。
2. 使用“流程视图”方便管理和调整。右侧有“流程视图”的按钮，点击之后进入到流程视图，会把你之前的操作以流程图的方式进行展示



